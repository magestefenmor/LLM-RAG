 #  SystÃ¨me RAG avec Langchain, Llama et Chainlit

 ## Introduction

# ğŸ¤– Chatbot RAG basÃ© sur le Web Scraping et LlamaIndex  

Ce projet implÃ©mente un **systÃ¨me RAG (Retrieval-Augmented Generation)** permettant de rÃ©pondre aux questions en s'appuyant sur des articles collectÃ©s via **Web Scraping**.  

### **ğŸ› ï¸ Comment fonctionne notre pipeline ?**  
Le projet est structurÃ© en trois grandes Ã©tapes :  

1ï¸âƒ£ **Collecte des donnÃ©es (Web Scraping) ğŸ•¸ï¸**  
   - Extraction automatique d'articles via **BeautifulSoup4** et **requests**.  
   - Stockage des articles en format JSON pour traitement.  

2ï¸âƒ£ **Traitement et Indexation des documents ğŸ“‚**  
   - Nettoyage et prÃ©traitement des textes.  
   - GÃ©nÃ©ration d'embeddings avec **Hugging Face** (`all-MiniLM-L6-v2`).  
   - Indexation des documents avec **LlamaIndex** pour une recherche optimisÃ©e.  

3ï¸âƒ£ **Recherche et gÃ©nÃ©ration de rÃ©ponses ğŸ¤–**  
   - Recherche des documents les plus pertinents dans lâ€™index (**retriever**).  
   - GÃ©nÃ©ration de rÃ©sumÃ©s avec **Hugging Face** (`facebook/bart-large-cnn`).  
   - Affichage des rÃ©ponses via une interface **Chainlit**.  

---

### **ğŸ’¡ Technologies utilisÃ©es**
- **BeautifulSoup4** ğŸ•¸ï¸ : Scraping et extraction dâ€™articles.  
- **LlamaIndex** ğŸ”— : Indexation et recherche documentaire.  
- **Hugging Face** ğŸ¤— : GÃ©nÃ©ration dâ€™embeddings et de rÃ©sumÃ©s.  
- **Chainlit** ğŸ’¬ : Interface interactive pour discuter avec le chatbot.  
- **Python** ğŸ : Langage principal du projet.  

Le projet permet d'interagir avec un **chatbot intelligent** qui rÃ©pond aux questions en sâ€™appuyant sur des documents collectÃ©s et indexÃ©s.  



Instructions d'Installation et d'ExÃ©cution
1. CrÃ©ation d'un environnement virtuel
Avec Conda

Assurez-vous d'abord que Conda est installÃ© sur votre systÃ¨me. Ensuite, crÃ©ez et activez un environnement virtuel avec la commande suivante :

 - conda create -n .venv python=3.11 -y && conda activate .venv

Avec Python (pour Linux/OS)

 - python3 -m venv /path/to/new_env && source /path/to/new_env/bin/activate

2. Installation des dÃ©pendances

Installez les packages Python nÃ©cessaires en exÃ©cutant :

 - pip install -r requirements.txt

3. ExÃ©cution du web scraping

Pour effectuer le web scraping, lancez le script suivant :

 - python Scraping.py

(Vous pouvez Ã©galement utiliser le fichier article.csv si nÃ©cessaire.)

Ensuite, exÃ©cutez :

 - python Traitement.py

Finalement, exÃ©cutez :

 - python Stockage.py

4. CrÃ©ation des embeddings

Pour crÃ©er les embeddings et les stocker localement, utilisez la commande suivante :

 - python query_index.py

5. ExÃ©cution de l'interface utilisateur de l'application

Pour dÃ©marrer l'interface utilisateur, exÃ©cutez :

 - chainlit run apps.py -w








